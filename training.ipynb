{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:29:49.299550Z",
     "start_time": "2025-06-18T16:29:47.048698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.utils import load_img, img_to_array\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# --- COLOR SPACE UTILITIES ---\n",
    "def hex_to_rgb(hex_color):\n",
    "    return [int(hex_color[i:i+2], 16)/255.0 for i in (0, 2, 4)]\n",
    "\n",
    "def f(t):\n",
    "    delta = 6/29\n",
    "    return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4/29))\n",
    "\n",
    "def inv_f(t):\n",
    "    delta = 6/29\n",
    "    return np.where(t > delta, t**3, 3 * delta**2 * (t - 4/29))\n",
    "\n",
    "def inv_gamma_correct(c):\n",
    "    return np.where(c <= 0.0031308, 12.92 * c, 1.055 * np.power(c, 1/2.4) - 0.055)\n",
    "\n",
    "def lab_normalize(lab):\n",
    "    return (lab + np.array([0, 128, 128])) / np.array([100, 255, 255])\n",
    "\n",
    "def lab_unnorm(lab):\n",
    "    return lab * np.array([100, 255, 255]) - np.array([0, 128, 128])\n",
    "\n",
    "def lab_to_rgb(lab):\n",
    "    L, a, b = lab\n",
    "    fy = (L + 16) / 116\n",
    "    fx = fy + a / 500\n",
    "    fz = fy - b / 200\n",
    "    xyz = np.array([\n",
    "        0.95047 * inv_f(fx),\n",
    "        1.00000 * inv_f(fy),\n",
    "        1.08883 * inv_f(fz)\n",
    "    ])\n",
    "    rgb_lin = np.array([\n",
    "        3.2406 * xyz[0] - 1.5372 * xyz[1] - 0.4986 * xyz[2],\n",
    "        -0.9689 * xyz[0] + 1.8758 * xyz[1] + 0.0415 * xyz[2],\n",
    "        0.0557 * xyz[0] - 0.2040 * xyz[1] + 1.0570 * xyz[2]\n",
    "    ])\n",
    "    rgb = inv_gamma_correct(np.clip(rgb_lin, 0, 1))\n",
    "    return np.clip(rgb, 0, 1)\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#{:02x}{:02x}{:02x}'.format(int(rgb[0]*255), int(rgb[1]*255), int(rgb[2]*255))\n",
    "\n",
    "def convert_lab(image):\n",
    "    mask = image > 0.04045\n",
    "    img_linear = np.where(mask, ((image + 0.055) / 1.055) ** 2.4, image / 12.92)\n",
    "    R, G, B = img_linear[..., 0], img_linear[..., 1], img_linear[..., 2]\n",
    "    X = (0.4124564 * R + 0.3575761 * G + 0.1804375 * B) / 0.950489\n",
    "    Y = (0.2126729 * R + 0.7151522 * G + 0.0721750 * B) / 1.0\n",
    "    Z = (0.0193339 * R + 0.1191920 * G + 0.9503041 * B) / 1.088840\n",
    "    X, Y, Z = f(X), f(Y), f(Z)\n",
    "    L = 116.0 * Y - 16.0\n",
    "    a = 500.0 * (X - Y)\n",
    "    b = 200.0 * (Y - Z)\n",
    "    return np.stack([L, a, b], axis=-1)\n",
    "\n",
    "def make_dataset():\n",
    "    basedir = \"Data/Res_ColorPickerCustomPicker\"\n",
    "    rows = []\n",
    "\n",
    "    for file in os.listdir(basedir):\n",
    "        filepath = os.path.join(basedir, file)\n",
    "        if re.match(r\".*\\d{2}\\.txt\", file):\n",
    "            image_groups = defaultdict(list)  # key: image filename, value: list of color groups\n",
    "\n",
    "            with open(filepath, \"r\") as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if not parts:\n",
    "                        continue\n",
    "                    image = parts[0]\n",
    "                    colors = [c.strip(\",\").replace('#', '') for c in parts[1:]]\n",
    "                    image_groups[image].append(colors)\n",
    "\n",
    "            # Now for each image in this file, pad its color groups and add to the rows\n",
    "            for image, color_groups in image_groups.items():\n",
    "                while len(color_groups) < 5:\n",
    "                    color_groups.append([])\n",
    "\n",
    "                rows.append({\n",
    "                    'file': file,\n",
    "                    'image': image,\n",
    "                    'color_1': color_groups[0],\n",
    "                    'color_2': color_groups[1],\n",
    "                    'color_3': color_groups[2],\n",
    "                    'color_4': color_groups[3],\n",
    "                    'color_5': color_groups[4],\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n",
    "def hex_to_rgb_tuple(hex_color):\n",
    "    return mcolors.to_rgb(hex_color)"
   ],
   "id": "82bd60e5e41c5d24",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 18:29:47.270761: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-18 18:29:47.273485: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-18 18:29:47.280460: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750264187.292260   89214 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750264187.295709   89214 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750264187.307327   89214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750264187.307341   89214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750264187.307343   89214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750264187.307344   89214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-18 18:29:47.310800: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# Test Lab conversion\n",
    "rgb_color = np.array([0.5, 0.2, 0.8]) # Example RGB color\n",
    "lab_color = convert_lab(rgb_color)\n",
    "print(f\"RGB: {rgb_color}\")\n",
    "print(f\"Lab: {lab_color}\")\n",
    "\n",
    "# Convert back to RGB to check\n",
    "rgb_back = lab_to_rgb(lab_color)\n",
    "print(f\"RGB back from Lab: {rgb_back}\")\n",
    "\n",
    "# Test normalization and unnormalization\n",
    "normalized_lab = lab_normalize(lab_color)\n",
    "print(f\"Normalized Lab: {normalized_lab}\")\n",
    "\n",
    "unnormalized_lab = lab_unnorm(normalized_lab)\n",
    "print(f\"Unnormalized Lab: {unnormalized_lab}\")\n",
    "\n",
    "# Test with hex\n",
    "hex_color = \"ff0000\" # Red\n",
    "rgb_from_hex = hex_to_rgb(hex_color)\n",
    "print(f\"Hex: {hex_color}, RGB from hex: {rgb_from_hex}\")\n",
    "\n",
    "# Test hex to rgb tuple\n",
    "rgb_tuple_from_hex = hex_to_rgb_tuple(\"#\"+hex_color)\n",
    "print(f\"Hex: {hex_color}, RGB tuple from hex: {rgb_tuple_from_hex}\")\n",
    "\n",
    "# Test rgb to hex\n",
    "hex_from_rgb = rgb_to_hex(rgb_from_hex)\n",
    "print(f\"RGB: {rgb_from_hex}, Hex from RGB: {hex_from_rgb}\")"
   ],
   "id": "8f9f9ebfc0085f9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:30:03.459377Z",
     "start_time": "2025-06-18T16:30:01.240785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- DATA PREPARATION ---\n",
    "# Load and process your dataframe\n",
    "input_colors = 5\n",
    "basedir = \"Data/PhotosColorPicker/\"\n",
    "\n",
    "df = make_dataset()\n",
    "df['image_path'] = basedir + df['image']\n",
    "\n",
    "def load_image(path):\n",
    "    img = load_img(path, target_size=(128, 128))\n",
    "    rgb_norm = img_to_array(img) / 255.0\n",
    "    lab = convert_lab(rgb_norm)\n",
    "    return lab_normalize(lab)\n",
    "\n",
    "b = df.groupby(df['image']).sum()\n",
    "b = b[['color_1','color_2','color_3','color_4','color_5']]\n",
    "b = b.reset_index()\n",
    "b['image_path'] = basedir + b['image']\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "for c in range(1,6):\n",
    "    b[f\"norm_rgb_{c}\"] = b[f'color_{c}'].apply(lambda a : [hex_to_rgb(str(i)) for i in a])\n",
    "for c in range(1,6):\n",
    "    b[f\"lab_{c}\"] = b[f'norm_rgb_{c}'].apply(lambda a : [convert_lab(np.array(i)) for i in a])\n",
    "\n",
    "for c in range(1,6):\n",
    "    b[f\"norm_lab_{c}\"] = b[f'lab_{c}'].apply(lambda a : [lab_normalize(np.array(i)) for i in a])\n",
    "\n",
    "def cluster_image_colors(color_vectors, n_clusters=5):\n",
    "    # Convert to numpy array\n",
    "    color_array = np.array(color_vectors)\n",
    "\n",
    "    # Handle edge cases: if fewer vectors than clusters\n",
    "    if len(color_array) < n_clusters:\n",
    "        return color_array  # Just return raw vectors\n",
    "\n",
    "    # Apply KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(color_array)\n",
    "\n",
    "    return kmeans.cluster_centers_\n",
    "\n",
    "# Apply to each row (each image)\n",
    "b['color_palette_lab'] = b[f'norm_lab_{input_colors}'].apply(lambda x: cluster_image_colors(x, n_clusters=input_colors))\n",
    "b[\"color_paletter_rgb\"] = b['color_palette_lab'].apply(\n",
    "    lambda palette: [lab_to_rgb(lab_unnorm(color)) for color in palette]\n",
    ")\n",
    "c = b[\"color_paletter_rgb\"]\n",
    "\n",
    "image_tensors = tf.stack([load_image(path) for path in b['image_path']])\n",
    "labs = np.stack(b['color_palette_lab'].values)\n",
    "labels = np.array(labs.astype(np.float64)).reshape(-1, 3*input_colors)\n",
    "# TF dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_tensors, labels)).shuffle(buffer_size=len(image_tensors))\n",
    "val_size = int(0.2 * len(image_tensors))\n",
    "train_dataset = dataset.skip(val_size).batch(32)\n",
    "val_dataset = dataset.take(val_size).batch(32)"
   ],
   "id": "ba12e8faf4d4a4e5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 18:30:02.626297: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = make_dataset()\n",
    "b = a.groupby(a['image']).sum()\n",
    "b = b[['color_1','color_2','color_3','color_4','color_5']]\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "clusters = 5\n",
    "\n",
    "for c in range(1,6):\n",
    "    b[f\"norm_rgb_{c}\"] = b[f'color_{c}'].apply(lambda a : [hex_to_rgb(str(i)) for i in a])\n",
    "for c in range(1,6):\n",
    "    b[f\"lab_{c}\"] = b[f'norm_rgb_{c}'].apply(lambda a : [convert_lab(np.array(i)) for i in a])\n",
    "\n",
    "for c in range(1,6):\n",
    "    b[f\"norm_lab_{c}\"] = b[f'lab_{c}'].apply(lambda a : [lab_normalize(np.array(i)) for i in a])\n",
    "\n",
    "def cluster_image_colors(color_vectors, n_clusters=5):\n",
    "    # Convert to numpy array\n",
    "    color_array = np.array(color_vectors)\n",
    "\n",
    "    # Handle edge cases: if fewer vectors than clusters\n",
    "    if len(color_array) < n_clusters:\n",
    "        return color_array  # Just return raw vectors\n",
    "\n",
    "    # Apply KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(color_array)\n",
    "\n",
    "    return kmeans.cluster_centers_\n",
    "\n",
    "# Apply to each row (each image)\n",
    "b['color_palette_lab'] = b[f'norm_lab_{clusters}'].apply(lambda x: cluster_image_colors(x, n_clusters=clusters))\n",
    "b[\"color_paletter_rgb\"] = b['color_palette_lab'].apply(\n",
    "    lambda palette: [lab_to_rgb(lab_unnorm(color)) for color in palette]\n",
    ")\n",
    "c = b[\"color_paletter_rgb\"]\n",
    "print(b['color_palette_lab'])"
   ],
   "id": "fda4a8f8cbd19913",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:32:10.480711Z",
     "start_time": "2025-06-18T16:30:07.362205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- MODEL DEFINITION ---\n",
    "# model = models.Sequential([\n",
    "#     layers.Input(shape=(64, 64, 3)),\n",
    "#     layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(256, activation='relu'),\n",
    "#     layers.Dense(3*input_colors, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# model = models.Sequential([\n",
    "#     layers.Input(shape=(64, 64, 3)),\n",
    "#     layers.Conv2D(32, (7, 7), activation='relu'),\n",
    "#     layers.MaxPooling2D(2, 2),\n",
    "#     layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D(4, 4),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(3*256, activation='relu'),\n",
    "#     layers.Dropout(0.3),\n",
    "#     layers.Dense(3*input_colors, activation='sigmoid')  # Predict L, a, b\n",
    "# ])\n",
    "#\n",
    "# model = models.Sequential([\n",
    "#     layers.Input(shape=(64, 64, 3)),\n",
    "#     layers.Conv2D(16 * input_colors, (3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D(2, 2),\n",
    "#\n",
    "#     layers.Conv2D(32 * input_colors, (3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D(2, 2),\n",
    "#\n",
    "#     layers.Conv2D(64 * input_colors, (3, 3), activation='relu'),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Dense(3 * input_colors, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(128, 128, 3)),\n",
    "    layers.Conv2D(16 * input_colors, (3, 3), activation='relu'),\n",
    "    layers.AveragePooling2D(2, 2),\n",
    "\n",
    "    layers.Conv2D(32 * input_colors, (3, 3), activation='relu'),\n",
    "    layers.AveragePooling2D(2, 2),\n",
    "\n",
    "    layers.Conv2D(64 * input_colors, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3 * input_colors, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#!\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(amsgrad=True, learning_rate=1e-3), loss='mse')\n",
    "model.fit(train_dataset, epochs=100, validation_data=val_dataset)\n"
   ],
   "id": "80e68f506173859b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 387ms/step - loss: 0.0966 - val_loss: 0.0394\n",
      "Epoch 2/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 357ms/step - loss: 0.0373 - val_loss: 0.0419\n",
      "Epoch 3/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 342ms/step - loss: 0.0382 - val_loss: 0.0382\n",
      "Epoch 4/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 339ms/step - loss: 0.0362 - val_loss: 0.0349\n",
      "Epoch 5/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 348ms/step - loss: 0.0328 - val_loss: 0.0316\n",
      "Epoch 6/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 335ms/step - loss: 0.0331 - val_loss: 0.0314\n",
      "Epoch 7/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 343ms/step - loss: 0.0309 - val_loss: 0.0268\n",
      "Epoch 8/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 338ms/step - loss: 0.0322 - val_loss: 0.0301\n",
      "Epoch 9/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 341ms/step - loss: 0.0310 - val_loss: 0.0278\n",
      "Epoch 10/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 342ms/step - loss: 0.0304 - val_loss: 0.0292\n",
      "Epoch 11/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 347ms/step - loss: 0.0293 - val_loss: 0.0272\n",
      "Epoch 12/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 343ms/step - loss: 0.0279 - val_loss: 0.0269\n",
      "Epoch 13/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 342ms/step - loss: 0.0275 - val_loss: 0.0265\n",
      "Epoch 14/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 356ms/step - loss: 0.0268 - val_loss: 0.0220\n",
      "Epoch 15/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 350ms/step - loss: 0.0274 - val_loss: 0.0258\n",
      "Epoch 16/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 354ms/step - loss: 0.0254 - val_loss: 0.0239\n",
      "Epoch 17/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 335ms/step - loss: 0.0235 - val_loss: 0.0228\n",
      "Epoch 18/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 350ms/step - loss: 0.0235 - val_loss: 0.0246\n",
      "Epoch 19/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 359ms/step - loss: 0.0203 - val_loss: 0.0162\n",
      "Epoch 20/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 361ms/step - loss: 0.0188 - val_loss: 0.0172\n",
      "Epoch 21/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 351ms/step - loss: 0.0202 - val_loss: 0.0189\n",
      "Epoch 22/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 336ms/step - loss: 0.0186 - val_loss: 0.0145\n",
      "Epoch 23/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 350ms/step - loss: 0.0158 - val_loss: 0.0152\n",
      "Epoch 24/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 377ms/step - loss: 0.0155 - val_loss: 0.0151\n",
      "Epoch 25/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0143 - val_loss: 0.0106\n",
      "Epoch 26/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 345ms/step - loss: 0.0143 - val_loss: 0.0123\n",
      "Epoch 27/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 352ms/step - loss: 0.0123 - val_loss: 0.0139\n",
      "Epoch 28/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0123 - val_loss: 0.0136\n",
      "Epoch 29/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 346ms/step - loss: 0.0112 - val_loss: 0.0121\n",
      "Epoch 30/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 331ms/step - loss: 0.0108 - val_loss: 0.0064\n",
      "Epoch 31/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 355ms/step - loss: 0.0098 - val_loss: 0.0069\n",
      "Epoch 32/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0074 - val_loss: 0.0060\n",
      "Epoch 33/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0075 - val_loss: 0.0059\n",
      "Epoch 34/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 343ms/step - loss: 0.0080 - val_loss: 0.0058\n",
      "Epoch 35/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 351ms/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 36/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 349ms/step - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 37/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 342ms/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 38/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 349ms/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 39/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 341ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 40/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 349ms/step - loss: 0.0060 - val_loss: 0.0036\n",
      "Epoch 41/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 340ms/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 42/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 351ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 43/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 346ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 44/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 45/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 343ms/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 46/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 351ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 47/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 353ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 48/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 340ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 49/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 368ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 50/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 348ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 51/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 352ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 52/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 343ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 53/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 346ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 54/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 55/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 345ms/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 56/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 349ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 57/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 339ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 58/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 346ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 59/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 350ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 60/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 343ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 61/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 349ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 62/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 343ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 63/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 346ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 64/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 350ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 65/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 346ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 66/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 67/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 354ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 68/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 351ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 69/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 342ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 70/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 353ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 71/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 345ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 72/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 352ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 73/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 360ms/step - loss: 0.0018 - val_loss: 8.0780e-04\n",
      "Epoch 74/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 349ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 75/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 348ms/step - loss: 0.0016 - val_loss: 8.8667e-04\n",
      "Epoch 76/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0015 - val_loss: 8.4077e-04\n",
      "Epoch 77/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 78/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 351ms/step - loss: 0.0018 - val_loss: 9.8342e-04\n",
      "Epoch 79/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 346ms/step - loss: 0.0014 - val_loss: 8.7357e-04\n",
      "Epoch 80/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 353ms/step - loss: 0.0015 - val_loss: 8.2805e-04\n",
      "Epoch 81/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 339ms/step - loss: 0.0015 - val_loss: 7.3352e-04\n",
      "Epoch 82/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 343ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 83/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 347ms/step - loss: 0.0016 - val_loss: 7.3770e-04\n",
      "Epoch 84/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 338ms/step - loss: 0.0014 - val_loss: 8.8031e-04\n",
      "Epoch 85/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 342ms/step - loss: 0.0015 - val_loss: 8.4234e-04\n",
      "Epoch 86/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 350ms/step - loss: 0.0013 - val_loss: 8.9409e-04\n",
      "Epoch 87/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 350ms/step - loss: 0.0013 - val_loss: 7.2198e-04\n",
      "Epoch 88/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 347ms/step - loss: 0.0013 - val_loss: 8.2610e-04\n",
      "Epoch 89/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 345ms/step - loss: 0.0013 - val_loss: 7.2868e-04\n",
      "Epoch 90/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0012 - val_loss: 6.3564e-04\n",
      "Epoch 91/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 342ms/step - loss: 0.0012 - val_loss: 6.7834e-04\n",
      "Epoch 92/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 332ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 93/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0014 - val_loss: 6.4874e-04\n",
      "Epoch 94/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 95/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 351ms/step - loss: 0.0015 - val_loss: 6.3306e-04\n",
      "Epoch 96/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 348ms/step - loss: 0.0013 - val_loss: 8.0492e-04\n",
      "Epoch 97/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 343ms/step - loss: 0.0013 - val_loss: 7.3149e-04\n",
      "Epoch 98/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 343ms/step - loss: 0.0013 - val_loss: 7.1686e-04\n",
      "Epoch 99/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 339ms/step - loss: 0.0011 - val_loss: 6.8695e-04\n",
      "Epoch 100/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 345ms/step - loss: 0.0011 - val_loss: 5.6558e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4ca811c7d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:32:36.633988Z",
     "start_time": "2025-06-18T16:32:36.083376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- EVALUATION ---\n",
    "from colormath.color_objects import LabColor\n",
    "from colormath.color_diff import delta_e_cmc\n",
    "\n",
    "def mae(predictions, truth):\n",
    "    return np.mean(np.abs(predictions - truth))\n",
    "\n",
    "def rmse(predictions, truth):\n",
    "    return np.sqrt(np.mean((predictions - truth)**2))\n",
    "\n",
    "def safe_compare(predictions, truth):\n",
    "    eps = 1e-6\n",
    "    return np.mean(np.abs(predictions - truth) / (np.abs(truth) + eps), axis=0)\n",
    "\n",
    "all_preds = model.predict(tf.data.Dataset.from_tensor_slices(image_tensors).batch(32))\n",
    "val_predicts = model.predict(val_dataset)\n",
    "print(\"Compare %:\", safe_compare(val_predicts, labels[:len(val_predicts)]) * 100)\n",
    "print(\"MAE:\", mae(val_predicts, labels[:len(val_predicts)]))\n",
    "print(\"RMSE:\", rmse(val_predicts, labels[:len(val_predicts)]))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    p = (((val_predicts[i])))\n",
    "    t = ((labels[i]))\n",
    "    print(\"Predicted:\", rgb_to_hex(p), \"True:\", rgb_to_hex(t))\n",
    "# --- PREDICTION VISUALIZATION ---\n"
   ],
   "id": "e5e8cbff7390ac6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 131ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 104ms/step\n",
      "Compare %: [ 52.93244991  22.50814228  32.52095268 175.19839426  17.67816784\n",
      "  59.44566519 139.33933619  24.10274764  17.6882804  330.54484584\n",
      "  22.58517992  35.23137443 109.75336908  18.62607945  17.81693419]\n",
      "MAE: 0.1893019629664349\n",
      "RMSE: 0.2643755979878178\n",
      "Predicted: #c18685 True: #ea6bce\n",
      "Predicted: #c27cbf True: #79b9a0\n",
      "Predicted: #947794 True: #cf58ad\n",
      "Predicted: #ea8983 True: #72bda4\n",
      "Predicted: #6eba3a True: #ef7d81\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:34:21.845851Z",
     "start_time": "2025-06-18T16:34:21.551447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Predict on new image\n",
    "#model = keras.saving.load_model(\"model.keras\")\n",
    "def show_colors(hex_list, titles=None):\n",
    "    fig, ax = plt.subplots(1, len(hex_list), figsize=(len(hex_list) * 2, 2))\n",
    "    if len(hex_list) == 1:\n",
    "        ax = [ax]\n",
    "    for i, hex_color in enumerate(hex_list):\n",
    "        rgb = np.array([[hex_to_rgb_tuple(hex_color)]])\n",
    "        ax[i].imshow(rgb)\n",
    "        ax[i].axis(\"off\")\n",
    "        if titles:\n",
    "            ax[i].set_title(titles[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "file = \"000000461404.jpg\"\n",
    "image_path = f\"Data/PhotosColorPicker/{file}\"\n",
    "\n",
    "image = load_img(image_path, target_size=(128, 128))\n",
    "img_array = img_to_array(image) / 255.0\n",
    "lab_image = convert_lab(img_array)\n",
    "lab_normed = lab_normalize(lab_image)\n",
    "input_arr = np.expand_dims(lab_normed, axis=0)\n",
    "prediction = model.predict(input_arr).reshape(input_colors,3)\n",
    "lab_pred = [lab_unnorm(i) for i in prediction]\n",
    "rgb_pred = [lab_to_rgb(i) for i in lab_pred]\n",
    "pred_hex = [rgb_to_hex(i) for i in rgb_pred]\n",
    "\n",
    "true_rgb = [i for i in b[b['image'] == file][\"color_paletter_rgb\"].iloc[0]]\n",
    "true_hex = [rgb_to_hex(i) for i in true_rgb]\n",
    "print(\"Predicted color:\", pred_hex)\n",
    "print(\"True color:\", true_hex)\n",
    "titles = [f\"Predicted {i+1}\" for i in range(len(pred_hex))]\n",
    "show_colors(pred_hex, titles)\n",
    "titles = [f\"True {i+1}\" for i in range(len(true_hex))]\n",
    "show_colors(true_hex, titles)"
   ],
   "id": "883c8d05289f6ccc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "Predicted color: ['#77356e', '#cdde9a', '#9b641c', '#ad6d58', '#bca5a2']\n",
      "True color: ['#07090d', '#abb5b1', '#464b41', '#eaeae9', '#777f7d']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model.compile(optimizer=tf.keras.optimizers.Adam(amsgrad=True, learning_rate=1e-3), loss='mse')\n",
    "# model = keras.saving.load_model(\"model.keras\")\n",
    "model.fit(train_dataset, epochs=10, validation_data=val_dataset)"
   ],
   "id": "1fe3d29ac117972b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.save(\"avg.keras\")",
   "id": "fb68ffb0cbaf4df8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
