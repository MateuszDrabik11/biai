{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T17:21:50.022Z",
     "start_time": "2025-06-27T17:21:46.487520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.utils import load_img, img_to_array\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "#functions that converts string with hexadecimal color in 24-bit rgb space into array of integers corresponding to the input\n",
    "#example:\n",
    "#a = hex_to_rgb(\"ff0000\")\n",
    "#print(a)\n",
    "#[255,0,0]\n",
    "def hex_to_rgb(hex_color):\n",
    "    return [int(hex_color[i:i+2], 16)/255.0 for i in (0, 2, 4)]\n",
    "\n",
    "#function used in conversion from rgb and lab color space\n",
    "def f(t):\n",
    "    delta = 6/29\n",
    "    return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4/29))\n",
    "#function used in conversion from lab and rgb color space\n",
    "def inv_f(t):\n",
    "    delta = 6/29\n",
    "    return np.where(t > delta, t**3, 3 * delta**2 * (t - 4/29))\n",
    "#inversion of gamma correction function\n",
    "def inv_gamma_correct(c):\n",
    "    return np.where(c <= 0.0031308, 12.92 * c, 1.055 * np.power(c, 1/2.4) - 0.055)\n",
    "#function normalizes color in lab space\n",
    "#l_in = <0;100>\n",
    "#a_in = <-127;128>\n",
    "#b_in = <-127;128>\n",
    "#l_out,a_out,b_out = <0;1>\n",
    "def lab_normalize(lab):\n",
    "    return (lab + np.array([0, 128, 128])) / np.array([100, 255, 255])\n",
    "#function takes normalized lab values and returns denormalized values\n",
    "def lab_unnorm(lab):\n",
    "    return lab * np.array([100, 255, 255]) - np.array([0, 128, 128])\n",
    "#function takes denormalized lab values and returns normalized rgb\n",
    "def lab_to_rgb(lab):\n",
    "    L, a, b = lab\n",
    "    fy = (L + 16) / 116\n",
    "    fx = fy + a / 500\n",
    "    fz = fy - b / 200\n",
    "    xyz = np.array([\n",
    "        0.95047 * inv_f(fx),\n",
    "        1.00000 * inv_f(fy),\n",
    "        1.08883 * inv_f(fz)\n",
    "    ])\n",
    "    rgb_lin = np.array([\n",
    "        3.2406 * xyz[0] - 1.5372 * xyz[1] - 0.4986 * xyz[2],\n",
    "        -0.9689 * xyz[0] + 1.8758 * xyz[1] + 0.0415 * xyz[2],\n",
    "        0.0557 * xyz[0] - 0.2040 * xyz[1] + 1.0570 * xyz[2]\n",
    "    ])\n",
    "    rgb = inv_gamma_correct(np.clip(rgb_lin, 0, 1))\n",
    "    return np.clip(rgb, 0, 1)\n",
    "#function takes an array of normalized rgb values and returns string that represents this color in hex\n",
    "#example:\n",
    "#in = [0,0,1]\n",
    "#print(rgb_to_hex(in))\n",
    "#\"#0000ff\"\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#{:02x}{:02x}{:02x}'.format(int(rgb[0]*255), int(rgb[1]*255), int(rgb[2]*255))\n",
    "#function converts from normalized rgb to lab color space and stacks those values into one array\n",
    "def convert_lab(image):\n",
    "    mask = image > 0.04045\n",
    "    img_linear = np.where(mask, ((image + 0.055) / 1.055) ** 2.4, image / 12.92)\n",
    "    R, G, B = img_linear[..., 0], img_linear[..., 1], img_linear[..., 2]\n",
    "    X = (0.4124564 * R + 0.3575761 * G + 0.1804375 * B) / 0.950489\n",
    "    Y = (0.2126729 * R + 0.7151522 * G + 0.0721750 * B) / 1.0\n",
    "    Z = (0.0193339 * R + 0.1191920 * G + 0.9503041 * B) / 1.088840\n",
    "    X, Y, Z = f(X), f(Y), f(Z)\n",
    "    L = 116.0 * Y - 16.0\n",
    "    a = 500.0 * (X - Y)\n",
    "    b = 200.0 * (Y - Z)\n",
    "    return np.stack([L, a, b], axis=-1)\n",
    "\n",
    "#function reads data from Res_ColorPickerCustomPicker/ with user choice describing the pictures and returns a dataframe with file from where the data is from, image, and selected colors\n",
    "#example row\n",
    "#file='AdrianR_2025_03_20-13_05_22.txt', image='000000010432', color_1 = ['0000ff'], color_2 = ['0000ff','00ff00'], color_3= ['0000ff','00ff00','ff0000'], ...\n",
    "def make_dataset():\n",
    "    basedir = \"Data/Res_ColorPickerCustomPicker\"\n",
    "    rows = []\n",
    "\n",
    "    for file in os.listdir(basedir):\n",
    "        filepath = os.path.join(basedir, file)\n",
    "        if re.match(r\".*\\d{2}\\.txt\", file):\n",
    "            image_groups = defaultdict(list)  # key: image filename, value: list of color groups\n",
    "\n",
    "            with open(filepath, \"r\") as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if not parts:\n",
    "                        continue\n",
    "                    image = parts[0]\n",
    "                    colors = [c.strip(\",\").replace('#', '') for c in parts[1:]]\n",
    "                    image_groups[image].append(colors)\n",
    "\n",
    "            # Now for each image in this file, pad its color groups and add to the rows\n",
    "            for image, color_groups in image_groups.items():\n",
    "                while len(color_groups) < 5:\n",
    "                    color_groups.append([])\n",
    "\n",
    "                rows.append({\n",
    "                    'file': file,\n",
    "                    'image': image,\n",
    "                    'color_1': color_groups[0],\n",
    "                    'color_2': color_groups[1],\n",
    "                    'color_3': color_groups[2],\n",
    "                    'color_4': color_groups[3],\n",
    "                    'color_5': color_groups[4],\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "#function splits array into a tuple\n",
    "def hex_to_rgb_tuple(hex_color):\n",
    "    return mcolors.to_rgb(hex_color)"
   ],
   "id": "82bd60e5e41c5d24",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 19:21:46.935179: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-27 19:21:47.059958: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-27 19:21:47.098442: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751044907.137863  178526 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751044907.148596  178526 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751044907.183304  178526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751044907.183320  178526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751044907.183322  178526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751044907.183324  178526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-27 19:21:47.188876: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T17:21:56.009839Z",
     "start_time": "2025-06-27T17:21:53.554979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#number of colors that are being predicted be neural network\n",
    "input_colors = 5\n",
    "#directory where the pictures are stored\n",
    "basedir = \"Data/PhotosColorPicker/\"\n",
    "\n",
    "df = make_dataset()\n",
    "#extend dataframe by a column with path to each picture\n",
    "df['image_path'] = basedir + df['image']\n",
    "#function to load pictures and convert colors from rgb to normalized lab\n",
    "def load_image(path):\n",
    "    img = load_img(path, target_size=(128, 128))\n",
    "    rgb_norm = img_to_array(img) / 255.0\n",
    "    lab = convert_lab(rgb_norm)\n",
    "    return lab_normalize(lab)\n",
    "\n",
    "#group colors by image and collect them into one array for number of selected colors\n",
    "b = df.groupby(df['image']).sum()\n",
    "b = b[['color_1','color_2','color_3','color_4','color_5']]\n",
    "b = b.reset_index()\n",
    "b['image_path'] = basedir + b['image']\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#convert strings to corresponding rgb values\n",
    "for c in range(1,6):\n",
    "    b[f\"norm_rgb_{c}\"] = b[f'color_{c}'].apply(lambda a : [hex_to_rgb(str(i)) for i in a])\n",
    "#convert to lab\n",
    "for c in range(1,6):\n",
    "    b[f\"lab_{c}\"] = b[f'norm_rgb_{c}'].apply(lambda a : [convert_lab(np.array(i)) for i in a])\n",
    "#normalize lab values\n",
    "for c in range(1,6):\n",
    "    b[f\"norm_lab_{c}\"] = b[f'lab_{c}'].apply(lambda a : [lab_normalize(np.array(i)) for i in a])\n",
    "#function to make n clusters where n is numbers of colors predicted be neural network, used to find colors chosen by users. Middle of the cluster is selected as the truth\n",
    "def cluster_image_colors(color_vectors, n_clusters=5):\n",
    "    # Convert to numpy array\n",
    "    color_array = np.array(color_vectors)\n",
    "\n",
    "    # Handle edge cases: if fewer vectors than clusters\n",
    "    if len(color_array) < n_clusters:\n",
    "        return color_array  # Just return raw vectors\n",
    "\n",
    "    # Apply KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(color_array)\n",
    "\n",
    "    return kmeans.cluster_centers_\n",
    "\n",
    "#cluster colors, with normalized lab values\n",
    "b['color_palette_lab'] = b[f'norm_lab_{input_colors}'].apply(lambda x: cluster_image_colors(x, n_clusters=input_colors))\n",
    "#convert the truths into rgb format\n",
    "b[\"color_paletter_rgb\"] = b['color_palette_lab'].apply(\n",
    "    lambda palette: [lab_to_rgb(lab_unnorm(color)) for color in palette]\n",
    ")\n",
    "c = b[\"color_paletter_rgb\"]\n",
    "\n",
    "#load images and create datasets for nn training\n",
    "\n",
    "image_tensors = tf.stack([load_image(path) for path in b['image_path']])\n",
    "labs = np.stack(b['color_palette_lab'].values)\n",
    "labels = np.array(labs.astype(np.float64)).reshape(-1, 3*input_colors)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_tensors, labels)).shuffle(buffer_size=len(image_tensors))\n",
    "#split dataset in 20/80 proportion for training and validation\n",
    "val_size = int(0.2 * len(image_tensors))\n",
    "train_dataset = dataset.skip(val_size).batch(32)\n",
    "val_dataset = dataset.take(val_size).batch(32)"
   ],
   "id": "ba12e8faf4d4a4e5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 19:21:55.165771: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T17:31:11.562305Z",
     "start_time": "2025-06-27T17:30:08.985061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#model definition\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(128, 128, 3)),\n",
    "    layers.Conv2D(16 * input_colors, (3, 3), activation='relu'),\n",
    "    layers.AveragePooling2D(2, 2),\n",
    "\n",
    "    layers.Conv2D(32 * input_colors, (3, 3), activation='relu'),\n",
    "    layers.AveragePooling2D(2, 2),\n",
    "\n",
    "    layers.Conv2D(64 * input_colors, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3 * input_colors, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#learing\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(amsgrad=True, learning_rate=1e-3), loss=\"mse\")\n",
    "history = model.fit(train_dataset, epochs=50, validation_data=val_dataset)"
   ],
   "id": "80e68f506173859b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 369ms/step - loss: 0.1015 - val_loss: 0.0489\n",
      "Epoch 2/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0434 - val_loss: 0.0358\n",
      "Epoch 3/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 345ms/step - loss: 0.0348 - val_loss: 0.0308\n",
      "Epoch 4/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0339 - val_loss: 0.0332\n",
      "Epoch 5/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0340 - val_loss: 0.0348\n",
      "Epoch 6/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0330 - val_loss: 0.0335\n",
      "Epoch 7/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 354ms/step - loss: 0.0341 - val_loss: 0.0334\n",
      "Epoch 8/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 342ms/step - loss: 0.0321 - val_loss: 0.0338\n",
      "Epoch 9/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 354ms/step - loss: 0.0327 - val_loss: 0.0301\n",
      "Epoch 10/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 347ms/step - loss: 0.0317 - val_loss: 0.0297\n",
      "Epoch 11/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 340ms/step - loss: 0.0304 - val_loss: 0.0338\n",
      "Epoch 12/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 356ms/step - loss: 0.0296 - val_loss: 0.0330\n",
      "Epoch 13/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 361ms/step - loss: 0.0283 - val_loss: 0.0306\n",
      "Epoch 14/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 345ms/step - loss: 0.0269 - val_loss: 0.0241\n",
      "Epoch 15/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 341ms/step - loss: 0.0270 - val_loss: 0.0245\n",
      "Epoch 16/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 340ms/step - loss: 0.0255 - val_loss: 0.0225\n",
      "Epoch 17/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 341ms/step - loss: 0.0238 - val_loss: 0.0258\n",
      "Epoch 18/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 338ms/step - loss: 0.0232 - val_loss: 0.0198\n",
      "Epoch 19/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 342ms/step - loss: 0.0234 - val_loss: 0.0227\n",
      "Epoch 20/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 343ms/step - loss: 0.0213 - val_loss: 0.0193\n",
      "Epoch 21/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0200 - val_loss: 0.0196\n",
      "Epoch 22/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 351ms/step - loss: 0.0198 - val_loss: 0.0194\n",
      "Epoch 23/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 351ms/step - loss: 0.0178 - val_loss: 0.0187\n",
      "Epoch 24/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 357ms/step - loss: 0.0174 - val_loss: 0.0152\n",
      "Epoch 25/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344ms/step - loss: 0.0170 - val_loss: 0.0125\n",
      "Epoch 26/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 345ms/step - loss: 0.0156 - val_loss: 0.0153\n",
      "Epoch 27/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 355ms/step - loss: 0.0146 - val_loss: 0.0129\n",
      "Epoch 28/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 351ms/step - loss: 0.0125 - val_loss: 0.0112\n",
      "Epoch 29/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 354ms/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 30/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 345ms/step - loss: 0.0124 - val_loss: 0.0129\n",
      "Epoch 31/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 347ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 32/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 353ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 33/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 342ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 34/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 350ms/step - loss: 0.0108 - val_loss: 0.0060\n",
      "Epoch 35/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 355ms/step - loss: 0.0100 - val_loss: 0.0067\n",
      "Epoch 36/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 348ms/step - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 37/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 363ms/step - loss: 0.0084 - val_loss: 0.0052\n",
      "Epoch 38/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 342ms/step - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 39/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 341ms/step - loss: 0.0069 - val_loss: 0.0068\n",
      "Epoch 40/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 349ms/step - loss: 0.0081 - val_loss: 0.0093\n",
      "Epoch 41/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 357ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 42/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 351ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 43/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 357ms/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 44/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 346ms/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 45/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 346ms/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 46/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 348ms/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 47/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 347ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 48/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 355ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 49/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 357ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 50/50\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 349ms/step - loss: 0.0060 - val_loss: 0.0047\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T17:33:19.237041Z",
     "start_time": "2025-06-27T17:33:18.672150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#validation\n",
    "def mae(predictions, truth):\n",
    "    return np.mean(np.abs(predictions - truth))\n",
    "\n",
    "def rmse(predictions, truth):\n",
    "    return np.sqrt(np.mean((predictions - truth)**2))\n",
    "\n",
    "def safe_compare(predictions, truth):\n",
    "    eps = 1e-6\n",
    "    return np.mean(np.abs(predictions - truth) / (np.abs(truth) + eps), axis=0)\n",
    "\n",
    "#make predictions and calculate some values to evaluate model\n",
    "all_preds = model.predict(tf.data.Dataset.from_tensor_slices(image_tensors).batch(32))\n",
    "val_predicts = model.predict(val_dataset)\n",
    "print(\"Compare %:\", safe_compare(val_predicts, labels[:len(val_predicts)]) * 100)\n",
    "print(\"MAE:\", mae(val_predicts, labels[:len(val_predicts)]))\n",
    "print(\"RMSE:\", rmse(val_predicts, labels[:len(val_predicts)]))\n",
    "\n",
    "#print first 5 predicted colors and truths\n",
    "for i in range(5):\n",
    "    p = (((val_predicts[i])))\n",
    "    t = ((labels[i]))\n",
    "    print(\"Predicted:\", rgb_to_hex(p), \"True:\", rgb_to_hex(t))"
   ],
   "id": "e5e8cbff7390ac6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 136ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 104ms/step\n",
      "Compare %: [1.46890584e+02 2.55120029e+01 4.57523102e+01 1.21326630e+02\n",
      " 1.14367846e+01 2.74383872e+01 7.59795784e+01 1.93701510e+01\n",
      " 3.94085755e+01 4.69569991e+06 2.05447548e+01 2.33076206e+01\n",
      " 8.22147805e+01 2.44770191e+01 3.43127197e+01]\n",
      "MAE: 0.18162349804034492\n",
      "RMSE: 0.2463453076988366\n",
      "Predicted: #b9738e True: #f37e7e\n",
      "Predicted: #a6b1a9 True: #849f62\n",
      "Predicted: #667798 True: #a36e94\n",
      "Predicted: #d79184 True: #8f8f71\n",
      "Predicted: #1f7478 True: #59bd25\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T17:34:54.780094Z",
     "start_time": "2025-06-27T17:34:54.447810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#load pretrained model or use the trained one\n",
    "#model = keras.saving.load_model(\"model_5_colors.keras\")\n",
    "\n",
    "#function to display colors\n",
    "def show_colors(hex_list, titles=None):\n",
    "    fig, ax = plt.subplots(1, len(hex_list), figsize=(len(hex_list) * 2, 2))\n",
    "    if len(hex_list) == 1:\n",
    "        ax = [ax]\n",
    "    for i, hex_color in enumerate(hex_list):\n",
    "        rgb = np.array([[hex_to_rgb_tuple(hex_color)]])\n",
    "        ax[i].imshow(rgb)\n",
    "        ax[i].axis(\"off\")\n",
    "        if titles:\n",
    "            ax[i].set_title(titles[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "#file name\n",
    "file = \"000000014824.jpg\"\n",
    "#image path\n",
    "image_path = f\"Data/PhotosColorPicker/{file}\"\n",
    "\n",
    "#load file and convert to normalized lab\n",
    "image = load_img(image_path, target_size=(128, 128))\n",
    "img_array = img_to_array(image) / 255.0\n",
    "lab_image = convert_lab(img_array)\n",
    "lab_normed = lab_normalize(lab_image)\n",
    "input_arr = np.expand_dims(lab_normed, axis=0)\n",
    "#make prediction\n",
    "prediction = model.predict(input_arr).reshape(input_colors,3)\n",
    "#convert from lab to rgb\n",
    "lab_pred = [lab_unnorm(i) for i in prediction]\n",
    "rgb_pred = [lab_to_rgb(i) for i in lab_pred]\n",
    "pred_hex = [rgb_to_hex(i) for i in rgb_pred]\n",
    "#get truths from dataset\n",
    "true_rgb = [i for i in b[b['image'] == file][\"color_paletter_rgb\"].iloc[0]]\n",
    "true_hex = [rgb_to_hex(i) for i in true_rgb]\n",
    "#display comparison between prediction and truths\n",
    "print(\"Predicted color:\", pred_hex)\n",
    "print(\"True color:\", true_hex)\n",
    "titles = [f\"Predicted {i+1}\" for i in range(len(pred_hex))]\n",
    "show_colors(pred_hex, titles)\n",
    "titles = [f\"True {i+1}\" for i in range(len(true_hex))]\n",
    "show_colors(true_hex, titles)"
   ],
   "id": "883c8d05289f6ccc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "Predicted color: ['#949e4b', '#7487a4', '#86b7ae', '#3e436f', '#b1607f']\n",
      "True color: ['#9969af', '#c8362f', '#4432b0', '#9eeb70', '#b3bab8']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#make a graph off loss function over epochs\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ],
   "id": "4d5854fc3221f2ea",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
