{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T11:10:46.695791Z",
     "start_time": "2025-06-12T11:10:46.517585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.utils import load_img, img_to_array\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "# --- COLOR SPACE UTILITIES ---\n",
    "def hex_to_rgb(hex_color):\n",
    "    return [int(hex_color[i:i+2], 16)/255.0 for i in (0, 2, 4)]\n",
    "\n",
    "def f(t):\n",
    "    delta = 6/29\n",
    "    return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4/29))\n",
    "\n",
    "def inv_f(t):\n",
    "    delta = 6/29\n",
    "    return np.where(t > delta, t**3, 3 * delta**2 * (t - 4/29))\n",
    "\n",
    "def inv_gamma_correct(c):\n",
    "    return np.where(c <= 0.0031308, 12.92 * c, 1.055 * np.power(c, 1/2.4) - 0.055)\n",
    "\n",
    "def lab_normalize(lab):\n",
    "    return (lab + np.array([0, 128, 128])) / np.array([100, 255, 255])\n",
    "\n",
    "def lab_unnorm(lab):\n",
    "    return lab * np.array([100, 255, 255]) - np.array([0, 128, 128])\n",
    "\n",
    "def lab_to_rgb(lab):\n",
    "    L, a, b = lab\n",
    "    fy = (L + 16) / 116\n",
    "    fx = fy + a / 500\n",
    "    fz = fy - b / 200\n",
    "    xyz = np.array([\n",
    "        0.95047 * inv_f(fx),\n",
    "        1.00000 * inv_f(fy),\n",
    "        1.08883 * inv_f(fz)\n",
    "    ])\n",
    "    rgb_lin = np.array([\n",
    "        3.2406 * xyz[0] - 1.5372 * xyz[1] - 0.4986 * xyz[2],\n",
    "        -0.9689 * xyz[0] + 1.8758 * xyz[1] + 0.0415 * xyz[2],\n",
    "        0.0557 * xyz[0] - 0.2040 * xyz[1] + 1.0570 * xyz[2]\n",
    "    ])\n",
    "    rgb = inv_gamma_correct(np.clip(rgb_lin, 0, 1))\n",
    "    return np.clip(rgb, 0, 1)\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#{:02x}{:02x}{:02x}'.format(int(rgb[0]*255), int(rgb[1]*255), int(rgb[2]*255))\n",
    "\n",
    "def convert_lab(image):\n",
    "    mask = image > 0.04045\n",
    "    img_linear = np.where(mask, ((image + 0.055) / 1.055) ** 2.4, image / 12.92)\n",
    "    R, G, B = img_linear[..., 0], img_linear[..., 1], img_linear[..., 2]\n",
    "    X = (0.4124564 * R + 0.3575761 * G + 0.1804375 * B) / 0.950489\n",
    "    Y = (0.2126729 * R + 0.7151522 * G + 0.0721750 * B) / 1.0\n",
    "    Z = (0.0193339 * R + 0.1191920 * G + 0.9503041 * B) / 1.088840\n",
    "    X, Y, Z = f(X), f(Y), f(Z)\n",
    "    L = 116.0 * Y - 16.0\n",
    "    a = 500.0 * (X - Y)\n",
    "    b = 200.0 * (Y - Z)\n",
    "    return np.stack([L, a, b], axis=-1)\n",
    "\n",
    "def make_dataset():\n",
    "    basedir = \"Data/Res_ColorPickerCustomPicker\"\n",
    "    rows = []\n",
    "\n",
    "    for file in os.listdir(basedir):\n",
    "        filepath = os.path.join(basedir, file)\n",
    "        if re.match(r\".*\\d{2}\\.txt\", file):\n",
    "            image_groups = defaultdict(list)  # key: image filename, value: list of color groups\n",
    "\n",
    "            with open(filepath, \"r\") as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if not parts:\n",
    "                        continue\n",
    "                    image = parts[0]\n",
    "                    colors = [c.strip(\",\").replace('#', '') for c in parts[1:]]\n",
    "                    image_groups[image].append(colors)\n",
    "\n",
    "            # Now for each image in this file, pad its color groups and add to the rows\n",
    "            for image, color_groups in image_groups.items():\n",
    "                while len(color_groups) < 5:\n",
    "                    color_groups.append([])\n",
    "\n",
    "                rows.append({\n",
    "                    'file': file,\n",
    "                    'image': image,\n",
    "                    'color_1': color_groups[0],\n",
    "                    'color_2': color_groups[1],\n",
    "                    'color_3': color_groups[2],\n",
    "                    'color_4': color_groups[3],\n",
    "                    'color_5': color_groups[4],\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n",
    "def hex_to_rgb_tuple(hex_color):\n",
    "    return mcolors.to_rgb(hex_color)"
   ],
   "id": "82bd60e5e41c5d24",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T11:10:50.541994Z",
     "start_time": "2025-06-12T11:10:50.528382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# Test Lab conversion\n",
    "rgb_color = np.array([0.5, 0.2, 0.8]) # Example RGB color\n",
    "lab_color = convert_lab(rgb_color)\n",
    "print(f\"RGB: {rgb_color}\")\n",
    "print(f\"Lab: {lab_color}\")\n",
    "\n",
    "# Convert back to RGB to check\n",
    "rgb_back = lab_to_rgb(lab_color)\n",
    "print(f\"RGB back from Lab: {rgb_back}\")\n",
    "\n",
    "# Test normalization and unnormalization\n",
    "normalized_lab = lab_normalize(lab_color)\n",
    "print(f\"Normalized Lab: {normalized_lab}\")\n",
    "\n",
    "unnormalized_lab = lab_unnorm(normalized_lab)\n",
    "print(f\"Unnormalized Lab: {unnormalized_lab}\")\n",
    "\n",
    "# Test with hex\n",
    "hex_color = \"ff0000\" # Red\n",
    "rgb_from_hex = hex_to_rgb(hex_color)\n",
    "print(f\"Hex: {hex_color}, RGB from hex: {rgb_from_hex}\")\n",
    "\n",
    "# Test hex to rgb tuple\n",
    "rgb_tuple_from_hex = hex_to_rgb_tuple(\"#\"+hex_color)\n",
    "print(f\"Hex: {hex_color}, RGB tuple from hex: {rgb_tuple_from_hex}\")\n",
    "\n",
    "# Test rgb to hex\n",
    "hex_from_rgb = rgb_to_hex(rgb_from_hex)\n",
    "print(f\"RGB: {rgb_from_hex}, Hex from RGB: {hex_from_rgb}\")"
   ],
   "id": "8f9f9ebfc0085f9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB: [0.5 0.2 0.8]\n",
      "Lab: [ 40.04429601  60.25375574 -65.67457626]\n",
      "RGB back from Lab: [0.49997055 0.20007704 0.79992792]\n",
      "Normalized Lab: [0.40044296 0.73825002 0.24441343]\n",
      "Unnormalized Lab: [ 40.04429601  60.25375574 -65.67457626]\n",
      "Hex: ff0000, RGB from hex: [1.0, 0.0, 0.0]\n",
      "Hex: ff0000, RGB tuple from hex: (1.0, 0.0, 0.0)\n",
      "RGB: [1.0, 0.0, 0.0], Hex from RGB: #ff0000\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T11:11:13.513371Z",
     "start_time": "2025-06-12T11:10:54.087381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- DATA PREPARATION ---\n",
    "# Load and process your dataframe\n",
    "input_colors = 5\n",
    "\n",
    "df = make_dataset()\n",
    "\n",
    "print(df)\n",
    "df['lab'] = df['color_5'].apply(\n",
    "    lambda colors: [convert_lab(np.array(hex_to_rgb(c))) for c in colors]\n",
    ")\n",
    "basedir = \"Data/PhotosColorPicker/\"\n",
    "#df_grouped['lab'] = df_grouped['target_rgb'].apply(convert_lab)\n",
    "df['image_path'] = basedir + df['image']\n",
    "print(df)\n",
    "\n",
    "# Load image tensors\n",
    "def load_image(path):\n",
    "    img = load_img(path, target_size=(64, 64))\n",
    "    rgb_norm = img_to_array(img) / 255.0\n",
    "    lab = convert_lab(rgb_norm)\n",
    "    return lab_normalize(lab)\n",
    "\n",
    "color_df = pd.DataFrame(df['lab'].tolist(), columns=['a', 'b', 'c','d','e'])\n",
    "\n",
    "# Combine it back with the original DataFrame\n",
    "df_expanded = pd.concat([df[['image']], color_df], axis=1)\n",
    "\n",
    "# Group by image and take mean\n",
    "mean_colors = df_expanded.groupby('image')[['a', 'b', 'c','d','e']].mean().reset_index()\n",
    "\n",
    "df[\"data\"] = df_expanded[['a', 'b', 'c','d','e']].values.tolist()\n",
    "\n",
    "print(mean_colors)\n",
    "\n",
    "image_tensors = tf.stack([load_image(path) for path in df['image_path']])\n",
    "labs = np.stack(df['data'].values)\n",
    "labels = np.array(lab_normalize(labs).astype(np.float64)).reshape(-1, 3*input_colors)\n",
    "#labels.shape = (n,9)\n",
    "# TF dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_tensors, labels)).shuffle(buffer_size=len(image_tensors))\n",
    "val_size = int(0.2 * len(image_tensors))\n",
    "train_dataset = dataset.skip(val_size).batch(32)\n",
    "val_dataset = dataset.take(val_size).batch(32)"
   ],
   "id": "ba12e8faf4d4a4e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   file             image   color_1  \\\n",
      "0       AdrianR_2025_03_20-13_05_22.txt  000000010432.jpg  [af885a]   \n",
      "1       AdrianR_2025_03_20-13_05_22.txt  000000014824.jpg  [6a67c9]   \n",
      "2       AdrianR_2025_03_20-13_05_22.txt  000000022423.jpg  [b4c9a1]   \n",
      "3       AdrianR_2025_03_20-13_05_22.txt  000000023019.jpg  [ba78b6]   \n",
      "4       AdrianR_2025_03_20-13_05_22.txt  000000029255.jpg  [5951c6]   \n",
      "...                                 ...               ...       ...   \n",
      "1887  mehow270P_2025_03_25-10_16_23.txt  000000537131.jpg  [0c4c1d]   \n",
      "1888  mehow270P_2025_03_25-10_16_23.txt  000000547938.jpg  [000000]   \n",
      "1889  mehow270P_2025_03_25-10_16_23.txt  000000556123.jpg  [37e521]   \n",
      "1890  mehow270P_2025_03_25-10_16_23.txt  000000562160.jpg  [ffab20]   \n",
      "1891  mehow270P_2025_03_25-10_16_23.txt  000000572756.jpg  [367de5]   \n",
      "\n",
      "               color_2                   color_3  \\\n",
      "0     [af7a3e, FFFFFF]  [998b49, 636668, 5e8e51]   \n",
      "1     [6666c9, 4a49c9]  [6869c9, 4d50c9, 7833c9]   \n",
      "2     [b5d695, cfced6]  [bfd698, d4d2d6, d5d6b6]   \n",
      "3     [aa74ba, ba6c42]  [ba65af, ba6628, 696b6a]   \n",
      "4     [543bc6, 5e4b20]  [4736aa, 5e4c1f, 6776aa]   \n",
      "...                ...                       ...   \n",
      "1887  [084c0e, 000000]  [0e4c0a, 000000, c8c7cc]   \n",
      "1888  [000000, c6c8cc]  [000000, c8c7cc, FFFFFF]   \n",
      "1889  [4ae523, 0f4c0e]  [1a4c09, 59ff47, 91b28f]   \n",
      "1890  [ffaf1f, 000000]  [ffb72d, 000000, FFFFFF]   \n",
      "1891  [2a67e5, 9bff90]  [6381ff, 000000, aaff92]   \n",
      "\n",
      "                               color_4  \\\n",
      "0     [af9648, 707574, 498958, 555956]   \n",
      "1     [6d5ec9, 4b3fc9, 6525c9, 901bc9]   \n",
      "2     [b6d688, d3d3d6, c6d6bd, d0d6c5]   \n",
      "3     [d367cf, d36439, d3873e, 686b69]   \n",
      "4     [4736c1, 5e4a1a, 6651c1, c18850]   \n",
      "...                                ...   \n",
      "1887  [146611, 000000, cacacc, 72cc7a]   \n",
      "1888  [000000, e3e2e5, 2f6622, FFFFFF]   \n",
      "1889  [9db296, 57ff4b, 000000, c6ccca]   \n",
      "1890  [ffaa26, 000000, bfffb1, FFFFFF]   \n",
      "1891  [4c9bff, 000000, a5ff98, ff30d0]   \n",
      "\n",
      "                                       color_5  \n",
      "0     [96812d, 656867, 3e894d, 9b9694, c3c9c3]  \n",
      "1     [7655c9, 5434c9, 5721c9, 5e0fc9, 840bc9]  \n",
      "2     [d4d69e, bbd678, d4d6d5, 989b98, 727270]  \n",
      "3     [c46ec4, c48239, 8a76c4, 959695, 212120]  \n",
      "4     [4146c1, 63480e, 443d63, 7a66ad, ad9659]  \n",
      "...                                        ...  \n",
      "1887  [234c1e, 000000, 8ecc9a, c8c8cc, 7a7a7f]  \n",
      "1888  [000000, e3e3e5, 296622, c9c8cc, FFFFFF]  \n",
      "1889  [54e534, 000000, bcccc8, dce2e5, 939799]  \n",
      "1890  [d2ffb9, e5a324, 000000, 48ff36, FFFFFF]  \n",
      "1891  [e431ff, 3176ff, 000000, c2ffb9, 183314]  \n",
      "\n",
      "[1892 rows x 7 columns]\n",
      "                                   file             image   color_1  \\\n",
      "0       AdrianR_2025_03_20-13_05_22.txt  000000010432.jpg  [af885a]   \n",
      "1       AdrianR_2025_03_20-13_05_22.txt  000000014824.jpg  [6a67c9]   \n",
      "2       AdrianR_2025_03_20-13_05_22.txt  000000022423.jpg  [b4c9a1]   \n",
      "3       AdrianR_2025_03_20-13_05_22.txt  000000023019.jpg  [ba78b6]   \n",
      "4       AdrianR_2025_03_20-13_05_22.txt  000000029255.jpg  [5951c6]   \n",
      "...                                 ...               ...       ...   \n",
      "1887  mehow270P_2025_03_25-10_16_23.txt  000000537131.jpg  [0c4c1d]   \n",
      "1888  mehow270P_2025_03_25-10_16_23.txt  000000547938.jpg  [000000]   \n",
      "1889  mehow270P_2025_03_25-10_16_23.txt  000000556123.jpg  [37e521]   \n",
      "1890  mehow270P_2025_03_25-10_16_23.txt  000000562160.jpg  [ffab20]   \n",
      "1891  mehow270P_2025_03_25-10_16_23.txt  000000572756.jpg  [367de5]   \n",
      "\n",
      "               color_2                   color_3  \\\n",
      "0     [af7a3e, FFFFFF]  [998b49, 636668, 5e8e51]   \n",
      "1     [6666c9, 4a49c9]  [6869c9, 4d50c9, 7833c9]   \n",
      "2     [b5d695, cfced6]  [bfd698, d4d2d6, d5d6b6]   \n",
      "3     [aa74ba, ba6c42]  [ba65af, ba6628, 696b6a]   \n",
      "4     [543bc6, 5e4b20]  [4736aa, 5e4c1f, 6776aa]   \n",
      "...                ...                       ...   \n",
      "1887  [084c0e, 000000]  [0e4c0a, 000000, c8c7cc]   \n",
      "1888  [000000, c6c8cc]  [000000, c8c7cc, FFFFFF]   \n",
      "1889  [4ae523, 0f4c0e]  [1a4c09, 59ff47, 91b28f]   \n",
      "1890  [ffaf1f, 000000]  [ffb72d, 000000, FFFFFF]   \n",
      "1891  [2a67e5, 9bff90]  [6381ff, 000000, aaff92]   \n",
      "\n",
      "                               color_4  \\\n",
      "0     [af9648, 707574, 498958, 555956]   \n",
      "1     [6d5ec9, 4b3fc9, 6525c9, 901bc9]   \n",
      "2     [b6d688, d3d3d6, c6d6bd, d0d6c5]   \n",
      "3     [d367cf, d36439, d3873e, 686b69]   \n",
      "4     [4736c1, 5e4a1a, 6651c1, c18850]   \n",
      "...                                ...   \n",
      "1887  [146611, 000000, cacacc, 72cc7a]   \n",
      "1888  [000000, e3e2e5, 2f6622, FFFFFF]   \n",
      "1889  [9db296, 57ff4b, 000000, c6ccca]   \n",
      "1890  [ffaa26, 000000, bfffb1, FFFFFF]   \n",
      "1891  [4c9bff, 000000, a5ff98, ff30d0]   \n",
      "\n",
      "                                       color_5  \\\n",
      "0     [96812d, 656867, 3e894d, 9b9694, c3c9c3]   \n",
      "1     [7655c9, 5434c9, 5721c9, 5e0fc9, 840bc9]   \n",
      "2     [d4d69e, bbd678, d4d6d5, 989b98, 727270]   \n",
      "3     [c46ec4, c48239, 8a76c4, 959695, 212120]   \n",
      "4     [4146c1, 63480e, 443d63, 7a66ad, ad9659]   \n",
      "...                                        ...   \n",
      "1887  [234c1e, 000000, 8ecc9a, c8c8cc, 7a7a7f]   \n",
      "1888  [000000, e3e3e5, 296622, c9c8cc, FFFFFF]   \n",
      "1889  [54e534, 000000, bcccc8, dce2e5, 939799]   \n",
      "1890  [d2ffb9, e5a324, 000000, 48ff36, FFFFFF]   \n",
      "1891  [e431ff, 3176ff, 000000, c2ffb9, 183314]   \n",
      "\n",
      "                                                    lab  \\\n",
      "0     [[54.422765486775106, -1.7450313764740266, 46....   \n",
      "1     [[45.03257854954941, 40.43774755787, -55.90150...   \n",
      "2     [[84.25624988231306, -9.585949175486498, 27.52...   \n",
      "3     [[58.85848812291319, 46.6536223183559, -30.583...   \n",
      "4     [[36.6555263945179, 37.046502064639775, -65.05...   \n",
      "...                                                 ...   \n",
      "1887  [[28.431956152076488, -24.98570099379871, 22.7...   \n",
      "1888  [[0.0, 0.0, 0.0], [90.28762504916152, 0.356059...   \n",
      "1889  [[80.83220851540521, -68.48609912182229, 69.04...   \n",
      "1890  [[95.46459290192371, -26.581371829182853, 28.8...   \n",
      "1891  [[57.954962656552226, 87.90112099956826, -64.8...   \n",
      "\n",
      "                                   image_path  \n",
      "0     Data/PhotosColorPicker/000000010432.jpg  \n",
      "1     Data/PhotosColorPicker/000000014824.jpg  \n",
      "2     Data/PhotosColorPicker/000000022423.jpg  \n",
      "3     Data/PhotosColorPicker/000000023019.jpg  \n",
      "4     Data/PhotosColorPicker/000000029255.jpg  \n",
      "...                                       ...  \n",
      "1887  Data/PhotosColorPicker/000000537131.jpg  \n",
      "1888  Data/PhotosColorPicker/000000547938.jpg  \n",
      "1889  Data/PhotosColorPicker/000000556123.jpg  \n",
      "1890  Data/PhotosColorPicker/000000562160.jpg  \n",
      "1891  Data/PhotosColorPicker/000000572756.jpg  \n",
      "\n",
      "[1892 rows x 9 columns]\n",
      "               image                                                  a  \\\n",
      "0   000000010432.jpg  [83.41821512634262, -12.844086194552641, 71.32...   \n",
      "1   000000014824.jpg  [47.70476199469309, 45.92584299331203, -19.043...   \n",
      "2   000000022423.jpg  [68.18988704753211, -19.092682706307023, 19.64...   \n",
      "3   000000023019.jpg  [53.581220458182564, 27.342947505356154, -22.5...   \n",
      "4   000000029255.jpg  [45.95856379780174, 38.72436626165784, -55.201...   \n",
      "..               ...                                                ...   \n",
      "81  000000537131.jpg  [44.09964049709706, 30.391970597284523, 29.065...   \n",
      "82  000000547938.jpg  [43.53293543402995, -21.53295905695741, 20.541...   \n",
      "83  000000556123.jpg  [61.134482064185654, -20.60670576951075, 21.09...   \n",
      "84  000000562160.jpg  [63.002698724219044, 32.25734330935754, 39.149...   \n",
      "85  000000572756.jpg  [67.19430692138555, 25.582457863873834, -24.47...   \n",
      "\n",
      "                                                    b  \\\n",
      "0   [37.46383437833644, -6.365672988622526, 18.760...   \n",
      "1   [47.2321293568159, 42.40253030888267, -27.3797...   \n",
      "2   [63.368020508326914, -18.933148171290295, 20.8...   \n",
      "3   [42.391125490696226, 17.768305355326632, -10.2...   \n",
      "4   [53.06686706620389, 13.315961560752038, -23.27...   \n",
      "..                                                ...   \n",
      "81  [47.13384188470388, 31.426549093689605, 46.716...   \n",
      "82  [47.390294941672785, -4.830589779505852, 12.33...   \n",
      "83  [52.8837165495587, -5.793255977584147, 13.6691...   \n",
      "84  [54.754255410282845, 21.44653611453273, 29.752...   \n",
      "85  [71.10554202068892, 20.416744289335636, -25.00...   \n",
      "\n",
      "                                                    c  \\\n",
      "0   [67.60850946600318, -21.410777302098975, 39.10...   \n",
      "1   [48.659866402229994, 36.37607332212543, -14.37...   \n",
      "2   [57.01939341553872, -11.500100427088567, 14.79...   \n",
      "3   [52.013915915284336, 21.3370822295662, 1.70937...   \n",
      "4   [51.36032140968277, 17.913323660763577, -19.58...   \n",
      "..                                                ...   \n",
      "81  [55.55405748113439, 10.139665040661852, 15.639...   \n",
      "82  [36.821985034840196, -2.1693545175909494, 12.6...   \n",
      "83  [51.02850171275026, -4.787787514006181, 21.337...   \n",
      "84  [47.43619146204127, 26.933460096564627, 13.643...   \n",
      "85  [63.637945419325895, 17.521297909460017, -25.0...   \n",
      "\n",
      "                                                    d  \\\n",
      "0   [68.41541458562175, -13.011098902907912, 18.06...   \n",
      "1   [56.498244938984584, 15.235130118788396, -5.85...   \n",
      "2   [70.59037253478455, -7.545171711528801, 11.898...   \n",
      "3   [39.729800980272195, 13.53511991067515, 0.7010...   \n",
      "4   [53.60239387286363, 2.1262156612354706, -8.026...   \n",
      "..                                                ...   \n",
      "81  [62.94712886630908, 4.035028344655507, 11.1362...   \n",
      "82  [66.50160141561088, -5.570102143138619, 24.472...   \n",
      "83  [55.6608046890178, -10.906261358828685, 20.569...   \n",
      "84  [55.827437006600924, 0.08249021058388645, 10.0...   \n",
      "85  [60.82911781528623, 9.473017300447639, -19.802...   \n",
      "\n",
      "                                                    e  \n",
      "0   [60.74360210213435, 3.999428225543514, 31.2051...  \n",
      "1   [67.25167538156326, -1.1317552403897762, 22.45...  \n",
      "2   [61.28030382078084, -5.970590163934352, 11.406...  \n",
      "3   [51.69507245308983, 20.98506381863436, 1.03761...  \n",
      "4   [62.21983312492268, 3.294802917950968, -4.7058...  \n",
      "..                                                ...  \n",
      "81  [67.26592793430416, -4.002010515443243, 11.561...  \n",
      "82  [66.07195550449852, 5.56584003166166, 20.46396...  \n",
      "83  [63.19423293966288, -6.505239383936239, 14.301...  \n",
      "84  [76.24525321744589, 0.13118764340995137, 26.44...  \n",
      "85  [64.25945889872692, 15.48812615755415, -5.0749...  \n",
      "\n",
      "[86 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 13:11:04.313907: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 185991168 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T11:15:51.000720Z",
     "start_time": "2025-06-12T11:11:16.826766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- MODEL DEFINITION ---\n",
    "# model = models.Sequential([\n",
    "#     layers.Input(shape=(64, 64, 3)),\n",
    "#     layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(256, activation='relu'),\n",
    "#     layers.Dense(3*input_colors, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# model = models.Sequential([\n",
    "#     layers.Input(shape=(64, 64, 3)),\n",
    "#     layers.Conv2D(32, (7, 7), activation='relu'),\n",
    "#     layers.MaxPooling2D(2, 2),\n",
    "#     layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D(4, 4),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(3*256, activation='relu'),\n",
    "#     layers.Dropout(0.3),\n",
    "#     layers.Dense(3*input_colors, activation='sigmoid')  # Predict L, a, b\n",
    "# ])\n",
    "#\n",
    "# model = models.Sequential([\n",
    "#     layers.Input(shape=(64, 64, 3)),\n",
    "#     layers.Conv2D(16 * input_colors, (3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D(2, 2),\n",
    "#\n",
    "#     layers.Conv2D(32 * input_colors, (3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D(2, 2),\n",
    "#\n",
    "#     layers.Conv2D(64 * input_colors, (3, 3), activation='relu'),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Dense(3 * input_colors, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(64, 64, 3)),\n",
    "    layers.Conv2D(16 * input_colors, (3, 3), activation='relu'),\n",
    "    layers.AveragePooling2D(2, 2),\n",
    "\n",
    "    layers.Conv2D(32 * input_colors, (3, 3), activation='relu'),\n",
    "    layers.AveragePooling2D(2, 2),\n",
    "\n",
    "    layers.Conv2D(64 * input_colors, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3 * input_colors, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#!\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(amsgrad=True, learning_rate=1e-3), loss='mse')\n",
    "model.fit(train_dataset, epochs=10, validation_data=val_dataset)\n"
   ],
   "id": "80e68f506173859b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 13:11:17.009520: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 185991168 exceeds 10% of free system memory.\n",
      "2025-06-12 13:11:19.338663: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 39362560 exceeds 10% of free system memory.\n",
      "2025-06-12 13:11:19.644344: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 24220800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 479ms/step - loss: 0.0409 - val_loss: 0.0385\n",
      "Epoch 2/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 489ms/step - loss: 0.0351 - val_loss: 0.0357\n",
      "Epoch 3/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 493ms/step - loss: 0.0341 - val_loss: 0.0343\n",
      "Epoch 4/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 469ms/step - loss: 0.0334 - val_loss: 0.0328\n",
      "Epoch 5/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 504ms/step - loss: 0.0337 - val_loss: 0.0334\n",
      "Epoch 6/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 542ms/step - loss: 0.0329 - val_loss: 0.0322\n",
      "Epoch 7/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 671ms/step - loss: 0.0334 - val_loss: 0.0322\n",
      "Epoch 8/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 674ms/step - loss: 0.0331 - val_loss: 0.0321\n",
      "Epoch 9/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 638ms/step - loss: 0.0326 - val_loss: 0.0319\n",
      "Epoch 10/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 488ms/step - loss: 0.0323 - val_loss: 0.0307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f290443cd50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T11:23:28.532906Z",
     "start_time": "2025-06-12T11:23:20.319608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- EVALUATION ---\n",
    "from colormath.color_objects import LabColor\n",
    "from colormath.color_diff import delta_e_cmc\n",
    "\n",
    "def mae(predictions, truth):\n",
    "    return np.mean(np.abs(predictions - truth))\n",
    "\n",
    "def rmse(predictions, truth):\n",
    "    return np.sqrt(np.mean((predictions - truth)**2))\n",
    "\n",
    "def safe_compare(predictions, truth):\n",
    "    eps = 1e-6\n",
    "    return np.mean(np.abs(predictions - truth) / (np.abs(truth) + eps), axis=0)\n",
    "\n",
    "all_preds = model.predict(tf.data.Dataset.from_tensor_slices(image_tensors).batch(32))\n",
    "val_predicts = model.predict(val_dataset)\n",
    "print(\"Compare %:\", safe_compare(val_predicts, labels[:len(val_predicts)]) * 100)\n",
    "print(\"MAE:\", mae(val_predicts, labels[:len(val_predicts)]))\n",
    "print(\"RMSE:\", rmse(val_predicts, labels[:len(val_predicts)]))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    p = (((val_predicts[i])))\n",
    "    t = ((labels[i]))\n",
    "    print(\"Predicted:\", rgb_to_hex(p), \"True:\", rgb_to_hex(t))\n",
    "# --- PREDICTION VISUALIZATION ---\n"
   ],
   "id": "e5e8cbff7390ac6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 106ms/step\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 117ms/step\n",
      "Compare %: [2.44659138e+06 2.29802925e+01 4.38701876e+01 1.60683868e+06\n",
      " 2.19310598e+01 3.40145836e+01 2.10828534e+06 1.88401159e+01\n",
      " 2.37177600e+01 2.57234151e+06 1.51493509e+01 2.41208832e+01\n",
      " 3.18986128e+06 1.53862144e+01 2.09407875e+01]\n",
      "MAE: 0.14440384119887412\n",
      "RMSE: 0.19450142621204114\n",
      "Predicted: #658b74 True: #8a7eae\n",
      "Predicted: #927290 True: #72a848\n",
      "Predicted: #c54eb6 True: #d6769b\n",
      "Predicted: #b278a1 True: #96ae61\n",
      "Predicted: #c472bc True: #5da53e\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T12:02:13.110239Z",
     "start_time": "2025-06-12T12:02:11.678480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Predict on new image\n",
    "#model = keras.saving.load_model(\"model.keras\")\n",
    "def show_colors(hex_list, titles=None):\n",
    "    fig, ax = plt.subplots(1, len(hex_list), figsize=(len(hex_list) * 2, 2))\n",
    "    if len(hex_list) == 1:\n",
    "        ax = [ax]\n",
    "    for i, hex_color in enumerate(hex_list):\n",
    "        rgb = np.array([[hex_to_rgb_tuple(hex_color)]])\n",
    "        ax[i].imshow(rgb)\n",
    "        ax[i].axis(\"off\")\n",
    "        if titles:\n",
    "            ax[i].set_title(titles[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "file = \"000000010432.jpg\"\n",
    "image_path = f\"Data/PhotosColorPicker/{file}\"\n",
    "image = load_img(image_path, target_size=(64, 64))\n",
    "img_array = img_to_array(image) / 255.0\n",
    "lab_image = convert_lab(img_array)\n",
    "lab_normed = lab_normalize(lab_image)\n",
    "input_arr = np.expand_dims(lab_normed, axis=0)\n",
    "prediction = model.predict(input_arr).reshape(input_colors,3)\n",
    "lab_pred = [lab_unnorm(i) for i in prediction]\n",
    "rgb_pred = [lab_to_rgb(i) for i in lab_pred]\n",
    "pred_hex = [rgb_to_hex(i) for i in rgb_pred]\n",
    "\n",
    "true_rgb = [lab_to_rgb(i) for i in df[df['image'] == file][\"lab\"].values[0]]\n",
    "true_hex = [rgb_to_hex(i) for i in true_rgb]\n",
    "print(\"Predicted color:\", pred_hex)\n",
    "print(\"True color:\", true_hex)\n",
    "titles = [f\"Predicted {i+1}\" for i in range(len(pred_hex))]\n",
    "show_colors(pred_hex, titles)\n",
    "titles = [f\"True {i+1}\" for i in range(len(true_hex))]\n",
    "show_colors(true_hex, titles)"
   ],
   "id": "883c8d05289f6ccc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 92ms/step\n",
      "Predicted color: ['#c6c347', '#616243', '#93a569', '#8a9b7d', '#a78962']\n",
      "True color: ['#95812d', '#646866', '#3d894c', '#9a9693', '#c2c9c2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8UAAADICAYAAADBREMvAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAADaZJREFUeJzt3X1o1nW/wPGPh3KkoYmWZPiU9jiR1DhUUCtSVOpoEvgAlhO7sbJHQsvIU5n5kBZRh+66FbKkPyoh6C5LtJLuTBJDbH8EPaBJoYU1cbrS3H7nn5Pkmd7Nbe663Of1gv2x365r+3wHHy7e23VtnYqiKAIAAAAS+o9SDwAAAAClIooBAABISxQDAACQligGAAAgLVEMAABAWqIYAACAtEQxAAAAaYliAAAA0hLFAAAApCWKAQAASCt1FHfq1KlZbxs2bCjpnJs3b44777wzRowYEaeffnp06tSppPPQcZ0KO9HY2BgrV66McePGRd++faNr164xZMiQWLBgQfz2228lm4uO6VTYiYiI5cuXR1VVVfTu3TsqKipi4MCBMX369NixY0dJ56LjOVV24s9+//33uPTSS6NTp06xbNmyUo9DB3Oq7ER1dfUx57r44otLOle5OK3UA5TSqlWrjnr/1VdfjXXr1jW5fskll7TzZEdbs2ZNrFixIoYOHRrnn39+fPXVVyWdh47rVNiJ+vr6mD59elxxxRVx++23xznnnBObNm2KRx99ND744IP48MMP/eCINnMq7ERExNatW2PgwIExbty46NGjR2zfvj2WL18e77zzTmzbti369OlT0vnoOE6Vnfiz559/Pnbu3FnqMeigTqWdqKioiBUrVhx1rXv37iWbp6wUHDFr1qyiOd+SAwcOtMs8f9i9e3dRX19fFCcwI7SFctyJgwcPFhs3bmxy/fHHHy8ioli3bl27zUI+5bgTx7Nly5YiIopFixaVehQ6sHLfiR9//LHo3r17MX/+/CIiiqVLl5ZkDvIo152YNm1a0bVr13b9mqeS1E+fbo5rr702hgwZEp9//nlcc8010aVLl3j44Ycj/u/pEo899liT+wwYMCCqq6uPurZ379647777om/fvlFRURGDBw+OJUuWRGNj41/O0Lt37zjjjDPa8FTQcqXeic6dO8dVV13V5PqECRMiIuLLL79s5QnhxJR6J45nwIABRz4vtKdy2omHHnooLrroopg6dWobnAxappx2oqGhIfbt29cGp+pYUj99url+/vnnGDt2bEyePDmmTp0avXv3PqH719fXR1VVVfzwww8xc+bM6NevX3z66acxd+7c2LVrVzz77LMnbXY4GcpxJ3bv3h0REb169Trh+0JrlctO/Pzzz9HQ0BA7d+6M+fPnR0TE9ddf36IzQWuUw05s3rw5Xnnllfjkk0+8rIaSK4edqK+vj27dukV9fX306NEjpkyZEkuWLIkzzzyzFSfrGERxM+zevTtefPHFmDlzZovu/8wzz8S3334bW7dujQsuuCAiImbOnBl9+vSJpUuXxgMPPBB9+/Zt46nh5CnHnXjqqaeiW7duMXbs2BbNBK1RLjtx3nnnxcGDByMiomfPnvHcc8/FqFGjWjQTtEapd6Ioirj77rtj0qRJceWVV/qjc5RcqXfi3HPPjTlz5sTw4cOjsbEx3n///XjhhRdi27ZtsWHDhjjttNxZ6OnTzVBRURHTp09v8f3ffPPNuPrqq6NHjx6xZ8+eI28jR46MhoaG+Pjjj9t0XjjZym0nFi5cGOvXr4/FixfHWWed1eK5oKXKZSfee++9WLNmTTz99NPRr1+/OHDgQItngtYo9U6sXLkyampqYsmSJS2eAdpSqXdi0aJFsXjx4pg4cWJMnjw5Vq5cGU8++WRs3LgxVq9e3eK5OorcPxJopvPOOy86d+7c4vt//fXX8cUXX8TZZ599zI//9NNPrZgO2l857cTrr78ejzzySMyYMSPuuOOOFs8ErVEuO3HddddFRMTYsWNj/PjxMWTIkDjzzDPjrrvuavFs0BKl3Il9+/bF3LlzY/bs2Z6JR9kol8eJP7v//vtj3rx5sX79+pg8eXKLZ+sIRHEznOgfuWpoaDjq/cbGxhg1alTMmTPnmLe/8MILWzUftLdy2Yl169bFrbfeGjfccEO8+OKLJzQTtKVy2Yk/GzRoUAwbNixee+01UUy7K+VOLFu2LA4dOhSTJk068rTp77//PiIiamtrY8eOHdGnT59WBQqcqHJ8nDjjjDOiZ8+e8csvv5zwfTsaUdwKPXr0aPJXPQ8dOhS7du066tqgQYNi//79MXLkyHaeENpXe+7EZ599FhMmTIjLL7883njjjfSvhaE8lfpx4tdffz3yGmMoB+2xEzt37oza2tqorKxs8rGFCxfGwoULY+vWrXHZZZe14ATQtkr5OFFXVxd79uw57m+fM/Ga4lYYNGhQk+fv/+Mf/2jyk52JEyfGpk2bYu3atU0+x969e+Pw4cMnfVZoD+21E19++WXccMMNMWDAgHjnnXf8yzLKVnvsxOHDh6O2trbJ9c2bN0dNTU1cfvnlrToDtKX22Il77rkn3nrrraPeXnrppYiIqK6ujrfeeisGDhzYZmeC1miPnfjtt9+irq6uyfUnnngiiqKIMWPGtOoMHYFfrbTCbbfdFrfffnvcfPPNMWrUqNi2bVusXbu2yb+EmT17drz99ttx4403RnV1dYwYMSIOHDgQNTU1sXr16tixY8e//Tcy3333XaxatSoiIrZs2RIREQsWLIiIiP79+8ctt9xyUs8JzdUeO1FXVxejR4+O2tramD17drz77rtHfXzQoEFx5ZVXntRzQnO1x07s378/+vbtG5MmTYrKysro2rVr1NTUxMsvvxzdu3ePefPmtdNp4a+1x04MHz48hg8fftS1P55GXVlZGTfddNNJPCGcmPbYid27d8ewYcNiypQpcfHFF0dExNq1a2PNmjUxZsyYGD9+fLuctawVHDFr1qzi/39LqqqqisrKymPevqGhoXjwwQeLXr16FV26dClGjx5dfPPNN0X//v2LadOmHXXburq6Yu7cucXgwYOLzp07F7169SquuuqqYtmyZcWhQ4f+7VwfffRRERHHfKuqqmqDk8OxleNObN++/bj7EBFNvg60pXLciYMHDxb33ntvMXTo0KJbt27F6aefXvTv37+YMWNGsX379jY6ORxbOe7Esfzx2LF06dIWnBKarxx3ora2tpg6dWoxePDgokuXLkVFRUVRWVlZLFy48IR3qaPqVBRFUeowBwAAgFLwmmIAAADSEsUAAACkJYoBAABISxQDAACQligGAAAgLVEMAABAWqIYAACAtE5r7g1fmD/05E4Cx3Dnf39R6hGO6293zCz1CCS0/O8vlXqE47rmqf8q9Qgk9PGcf5Z6hONa/vf/KfUIJPS3O+4q9QjH9a/N/yr1CCR09X9e/Ze38ZtiAAAA0hLFAAAApCWKAQAASEsUAwAAkJYoBgAAIC1RDAAAQFqiGAAAgLREMQAAAGmJYgAAANISxQAAAKQligEAAEhLFAMAAJCWKAYAACAtUQwAAEBaohgAAIC0RDEAAABpiWIAAADSEsUAAACkJYoBAABISxQDAACQligGAAAgLVEMAABAWqIYAACAtEQxAAAAaYliAAAA0hLFAAAApCWKAQAASEsUAwAAkJYoBgAAIC1RDAAAQFqiGAAAgLREMQAAAGmJYgAAANISxQAAAKQligEAAEhLFAMAAJCWKAYAACAtUQwAAEBaohgAAIC0RDEAAABpiWIAAADSEsUAAACkJYoBAABISxQDAACQligGAAAgLVEMAABAWqIYAACAtEQxAAAAaYliAAAA0hLFAAAApCWKAQAASEsUAwAAkJYoBgAAIC1RDAAAQFqiGAAAgLREMQAAAGmJYgAAANISxQAAAKQligEAAEhLFAMAAJCWKAYAACAtUQwAAEBaohgAAIC0RDEAAABpiWIAAADSEsUAAACkJYoBAABISxQDAACQligGAAAgLVEMAABAWqIYAACAtEQxAAAAaYliAAAA0hLFAAAApCWKAQAASEsUAwAAkJYoBgAAIC1RDAAAQFqiGAAAgLREMQAAAGmJYgAAANISxQAAAKQligEAAEhLFAMAAJCWKAYAACAtUQwAAEBaohgAAIC0RDEAAABpiWIAAADSEsUAAACkJYoBAABISxQDAACQligGAAAgLVEMAABAWqIYAACAtEQxAAAAaYliAAAA0hLFAAAApCWKAQAASEsUAwAAkJYoBgAAIC1RDAAAQFqiGAAAgLREMQAAAGmJYgAAANISxQAAAKQligEAAEhLFAMAAJCWKAYAACAtUQwAAEBaohgAAIC0RDEAAABpiWIAAADSEsUAAACkJYoBAABISxQDAACQligGAAAgLVEMAABAWqIYAACAtEQxAAAAaYliAAAA0hLFAAAApCWKAQAASEsUAwAAkJYoBgAAIC1RDAAAQFqiGAAAgLREMQAAAGmJYgAAANISxQAAAKQligEAAEhLFAMAAJCWKAYAACAtUQwAAEBaohgAAIC0RDEAAABpiWIAAADSEsUAAACkJYoBAABISxQDAACQligGAAAgLVEMAABAWqIYAACAtEQxAAAAaYliAAAA0hLFAAAApCWKAQAASEsUAwAAkJYoBgAAIC1RDAAAQFqiGAAAgLREMQAAAGmJYgAAANISxQAAAKQligEAAEhLFAMAAJCWKAYAACCtTkVRFKUeAgAAAErBb4oBAABISxQDAACQligGAAAgLVEMAABAWqIYAACAtEQxAAAAaYliAAAA0hLFAAAApCWKAQAASOt/AfCLcZxWWALIAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T11:22:54.690641Z",
     "start_time": "2025-06-12T11:17:55.331273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model.compile(optimizer=tf.keras.optimizers.Adam(amsgrad=True, learning_rate=1e-3), loss='mse')\n",
    "# model = keras.saving.load_model(\"model.keras\")\n",
    "model.fit(train_dataset, epochs=10, validation_data=val_dataset)"
   ],
   "id": "1fe3d29ac117972b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 444ms/step - loss: 0.0321 - val_loss: 0.0308\n",
      "Epoch 2/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 459ms/step - loss: 0.0322 - val_loss: 0.0316\n",
      "Epoch 3/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 503ms/step - loss: 0.0322 - val_loss: 0.0306\n",
      "Epoch 4/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 461ms/step - loss: 0.0315 - val_loss: 0.0333\n",
      "Epoch 5/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 472ms/step - loss: 0.0318 - val_loss: 0.0302\n",
      "Epoch 6/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 477ms/step - loss: 0.0318 - val_loss: 0.0313\n",
      "Epoch 7/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 473ms/step - loss: 0.0319 - val_loss: 0.0310\n",
      "Epoch 8/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 481ms/step - loss: 0.0316 - val_loss: 0.0304\n",
      "Epoch 9/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 478ms/step - loss: 0.0314 - val_loss: 0.0311\n",
      "Epoch 10/10\n",
      "\u001B[1m48/48\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 475ms/step - loss: 0.0323 - val_loss: 0.0324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f2907148d90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T11:22:58.825143Z",
     "start_time": "2025-06-12T11:22:58.702495Z"
    }
   },
   "cell_type": "code",
   "source": "model.save(\"avg.keras\")",
   "id": "fb68ffb0cbaf4df8",
   "outputs": [],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
